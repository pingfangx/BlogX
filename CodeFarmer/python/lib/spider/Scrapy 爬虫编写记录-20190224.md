经常不写手生。


# Spider
    新建类
    指定名字 name
    
    在 def start_requests(self): 中执行请求
    yield scrapy.Request(url=url)
    

## 解析
    在 def parse(self, response): 中解析结果
    可以使用 xpath 也可以使用 bs4
    解析后 yield item
    
# Item
    item 继承 BaseItem 
    使用 scrapy.Field() 添加要保存的字段
    
    
# Pipeline
    继承 BasePostgreSQLPipeline
    指定 item
    
    在 spider 中通过的 custom_settings 设置
    负责保存
    
# 运行