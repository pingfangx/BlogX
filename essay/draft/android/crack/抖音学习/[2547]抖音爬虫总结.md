以前刷抖音觉得浪费时间，想要爬取出来，直接按点赞数排序，看看点赞多的就行。  
抖音早已卸载，这个爬虫计划却一直在进行。

# 0x00 进度
最早一次有记录的提交是 20180313，实际尝试爬取可能更早  
但是被网络请求的参数校验阻挠，一直难以进展  
20180613 拜读多篇博文，正式攻破加密算法，开始写爬虫  
20180615 爬虫完成，但是连续爬取一段时间后， ip 总是会被禁，严重影响爬虫效率  
20180616 爬虫稳定（龟速）运行10天，爬取 100w 数据  
20180624 开始重构，添加代理并开始写爬代理的爬虫  
20180711 爬虫正式完工，成就感满满  
20180714 测试爬取效率，并发设为 16 时，ip 爬取速度略小于消耗速度  
实际维持有效 ip 数约 200 个。  
爬取数据约 2000 items/分钟，一天可爬约 288 w  
如果 ip 足够，不知道一天能不能冲击 1000 w。

## 补充
后来经过检查，上述的 100w 数据，是包括重复数据的，去重后只有 10 多 w。  
后来只好将请求地址拼上完整参数，继续爬取，但此时并发就不能用了  
因为有了用户标识，就不仅会从 ip 处理 ban，也会从身份标识 ban。  
所以又回归了稳定（龟速）爬取。

整理一下整个过程，也是留下多篇笔记，学到不少东西。  

后续的数据呈现、服务器定时爬取、App 端展示等计划就算了，到此已经浪费很多时间了。

![](https://pingfangx.github.io/resource/blogx/2547/1.png)

# 0x01 逆向网络请求
## jadx 的使用
## xposed 的使用
* 模拟器安装
* 模块开发
## IDA动态调试SO
## 加密算法分析

# 0x02 爬取
## 爬取
* Scrapy
* XPath
* 单元测试
* 并发与防 ban
* 多 spider 同时运行

## scrapy
* Items
* Spiders
* Pipeline
* Logging
* Middleware
* Settings

## 保存
* PostgresSQL
* asyncpg

## 并发
* 协程
* 多线程

# 0x03 代理
* 爬虫 spider
* 解析 parser  
端口解密
* 过滤 filter
* 校验 validator
* 管理 manager